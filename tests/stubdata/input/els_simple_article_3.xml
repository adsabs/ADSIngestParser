<doc:document xmlns:doc="http://www.elsevier.com/xml/document/schema" xmlns:dp="http://www.elsevier.com/xml/common/doc-properties/schema" xmlns:cps="http://www.elsevier.com/xml/common/consyn-properties/schema" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dct="http://purl.org/dc/terms/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:oa="http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/" xmlns:bam="http://vtw.elsevier.com/data/voc/ns/bam-vtw-1/" xmlns:cp="http://vtw.elsevier.com/data/ns/properties/Copyright-1/" xmlns:cja="http://www.elsevier.com/xml/cja/schema" xmlns:ja="http://www.elsevier.com/xml/ja/schema" xmlns:bk="http://www.elsevier.com/xml/bk/schema" xmlns:ce="http://www.elsevier.com/xml/common/schema" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:cals="http://www.elsevier.com/xml/common/cals/schema" xmlns:tb="http://www.elsevier.com/xml/common/table/schema" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/schema" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/schema" xmlns:xlink="http://www.w3.org/1999/xlink"><rdf:RDF><rdf:Description rdf:about="http://dx.doi.org/10.1016/j.plrev.2024.01.006"><dct:format>application/xml</dct:format><dct:title>The temporal dynamics of visual imagery and BCI: Comment on &#x201c;Visual mental imagery: Evidence for a heterarchical neural architecture&#x201d; by Spagna et&#160;al.</dct:title><dct:creator>Alice Mado Proverbio</dct:creator><dct:description>Physics of Life Reviews 48 (2024) 174-175. doi:10.1016/j.plrev.2024.01.006</dct:description><prism:aggregationType>journal</prism:aggregationType><prism:publicationName>Physics of Life Reviews</prism:publicationName><prism:copyright>&#169; 2024 Elsevier B.V. All rights reserved.</prism:copyright><dct:publisher>Elsevier B.V.</dct:publisher><prism:issn>1571-0645</prism:issn><prism:volume>48</prism:volume><prism:coverDisplayDate>March 2024</prism:coverDisplayDate><prism:pageRange>174-175</prism:pageRange><prism:startingPage>174</prism:startingPage><prism:endingPage>175</prism:endingPage><prism:doi>10.1016/j.plrev.2024.01.006</prism:doi><prism:url>http://dx.doi.org/10.1016/j.plrev.2024.01.006</prism:url><dct:identifier>doi:10.1016/j.plrev.2024.01.006</dct:identifier><dp:availableOnlineInformation><bam:availableOnline xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">2024-01-26T00:00:00.000Z</bam:availableOnline><bam:vorAvailableOnline xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">2024-02-01T00:00:00.000Z</bam:vorAvailableOnline></dp:availableOnlineInformation></rdf:Description></rdf:RDF><dp:document-properties><dp:aggregation-type>Journals</dp:aggregation-type><dp:version-number>S250.1</dp:version-number></dp:document-properties><ja:simple-article docsubtype="dis" version="5.6" xml:lang="en"><ja:item-info><ja:jid>PLREV</ja:jid><ja:aid>1550</ja:aid><ce:pii>S1571-0645(24)00006-X</ce:pii><ce:doi>10.1016/j.plrev.2024.01.006</ce:doi><ce:copyright type="full-transfer" year="2024">Elsevier B.V.</ce:copyright></ja:item-info><ja:simple-head><ce:title id="tte0002">The temporal dynamics of visual imagery and BCI: Comment on &#x201c;Visual mental imagery: Evidence for a heterarchical neural architecture&#x201d; by Spagna et&#160;al.</ce:title><ce:author-group id="aut0001"><ce:author id="au0001" author-id="S157106452400006X-6e4e337ba60d20d1826d227eb414db9f" orcid="0000-0002-5138-1523"><ce:given-name>Alice Mado</ce:given-name><ce:surname>Proverbio</ce:surname><ce:cross-ref id="crf0001" refid="cor0001"><ce:sup loc="post">&#x204e;</ce:sup></ce:cross-ref><ce:e-address id="ead0001" type="email" xlink:href="mailto:mado.proverbio@unimib.it">mado.proverbio@unimib.it</ce:e-address></ce:author><ce:affiliation id="aff0001" affiliation-id="S157106452400006X-22ecd453509301ea6510e645df2739ea"><ce:textfn id="cetextfn0001">Cognitive Electrophysiology Lab, Department of Psychology, University of Milano-Bicocca, Piazza dell'AteneoNuovo, 1, Milan 20162, Italy</ce:textfn><sa:affiliation><sa:organization>Cognitive Electrophysiology Lab</sa:organization><sa:organization>Department of Psychology</sa:organization><sa:organization>University of Milano-Bicocca</sa:organization><sa:address-line>Piazza dell'AteneoNuovo, 1</sa:address-line><sa:city>Milan</sa:city><sa:postal-code>20162</sa:postal-code><sa:country>Italy</sa:country></sa:affiliation><ce:source-text id="staff0001">Cognitive Electrophysiology Lab, Department of Psychology, University of Milano-Bicocca, Piazza dell'AteneoNuovo, 1, Milan 20162, Italy</ce:source-text></ce:affiliation><ce:correspondence id="cor0001"><ce:label>&#x204e;</ce:label><ce:text id="cetext0001">Correspondence to.</ce:text></ce:correspondence></ce:author-group><ce:date-received day="18" month="1" year="2024"/><ce:date-accepted day="23" month="1" year="2024"/></ja:simple-head><ja:body view="all"><ce:sections><ce:para id="para0001" view="all">In general, imagining takes much longer than perceiving, mental images are less sharp and defined than percepts, and the electrical or neurometabolic signals associated with imagining are of lower amplitude than those resulting from perception <ce:cross-ref id="crf0002" refid="bib0001">[1]</ce:cross-ref>. Furthermore, visual mental imagination (VMI) involves the anterior brain areas (e.g., the medial frontal cortex of the default-mode network) to a greater extent than perception, perhaps because what is imagined is necessarily conscious to the Self, which is not always the case with perception. Spagna et&#160;al. <ce:cross-ref id="crf0003" refid="bib0002">[2]</ce:cross-ref> recently published an insightful and groundbreaking review reporting that, apart from activation of the frontoparietal networks, the left fusiform gyrus and specific domain-related activations (such as the fusiform face area for faces and the lingual gyrus for color imagery), consistent activity in the early visual cortex for the various VMI domains could not be found across the literature.</ce:para><ce:section id="sec0001" view="all"><ce:label>1</ce:label><ce:section-title id="cesectitle0002">Temporal dynamics of VMI</ce:section-title><ce:para id="para0002" view="all">One aspect of VMI that is not discussed in this valuable paper by Spagna et&#160;al.&#160;<ce:cross-ref id="crf0004" refid="bib0002">[2]</ce:cross-ref>, mainly dealing with&#160;fMRI studies, is the temporal dynamics of imagery generation and development that cannot be understood without the aid of electromagnetic techniques such as MEG, EEG or Event-related potentials (ERPs). The use of temporal resolution enables the observation of processing flow direction and the activation order of anterior vs. posterior areas, which is linked to the voluntariness of VMI process in experimental paradigms. It also allows for monitoring latency and morphology similarity of evoked potentials across perception and imagery. As outlined by Dijkstra et&#160;al. <ce:cross-ref id="crf0005" refid="bib0003">[3]</ce:cross-ref> timing of voluntarily generating mental images would share some of the morphologic properties with sensory-evoked components. However, it would be delayed and be more anteriorly distributed <ce:cross-ref id="crf0006" refid="bib0004">[4]</ce:cross-ref> being the posterior brain not actually stimulated by external stimuli <ce:cross-ref id="crf0007" refid="bib0005">[5]</ce:cross-ref>.</ce:para></ce:section><ce:section id="sec0002" view="all"><ce:label>2</ce:label><ce:section-title id="cesectitle0003">Linking perception and imagination: brain potentials similarities</ce:section-title><ce:para id="para0003" view="all">Not many EEG/ERP studies have directly compared visual perception and imagination, but the results are encouraging. Page et&#160;al. <ce:cross-ref id="crf0008" refid="bib0006">[6]</ce:cross-ref> conducted a study where they measured evoked potentials during both perception and imagery of color patterns compared to black and white checkerboards. They analyzed the morphology of the evoked signals and found similarities between imagery and perception depending on the type of stimulus. Llorella et&#160;al. <ce:cross-ref id="crf0009" refid="bib0007">[7]</ce:cross-ref> also studied evoked potentials during imagination of various objects, such as a tree, a dog, an airplane, and a house. They used classification systems to analyze the data but only achieved partial success, with a 60&#160;% success rate in the classification. Finally, Lanfranco et&#160;al. <ce:cross-ref id="crf0010" refid="bib0008">[8]</ce:cross-ref> used multivariate decoding analysis to compare N170 ERP responses to faces that were hallucinated, imagined, or perceived under hypnosis. They found that a classifier was able to distinguish between the hallucinated and imagined conditions, specifically in the right occipito/temporal area. Recently, Proverbio et&#160;al. <ce:cross-ref id="crf0011" refid="bib0009">[9]</ce:cross-ref> estimated that it takes 300&#x2013;400&#160;ms to form a conscious image, also known as the imagery delay. They also found late-latency potentials that indexed distinct semantic domains of VMI, including infant faces, adult faces, animal faces, and human bodies, which were similar to perceptual ones. In another study <ce:cross-ref id="crf0012" refid="bib0010">[10]</ce:cross-ref>, the ERP markers of 12 recalled motivational states prompted by visual pictograms were investigated: namely visceral needs (hunger, thirst and sleep), somatosensory thermal and pain sensations (heat, cold, and pain), affective states (e.g., fear, sadness and joy) and secondary needs (e.g., desire to exercise, listen to music or play with friends). Overall, ERPs were smaller and more anteriorly distributed during imagery than perception, but showed some similarity in terms of lateralization, distribution, and category response, thus indicating some overlap in neural processing. In general, anterior frontal imagery-related N400 provided clear markers of subjects&#x2019; physiological needs and motivational states, especially cold, pain, and fear (but also sadness, the urgency to move, etc.).</ce:para></ce:section><ce:section id="sec0003" view="all"><ce:label>3</ce:label><ce:section-title id="cesectitle0004">Similarity between perception and VMI in active brain sources</ce:section-title><ce:para id="para0004" view="all">In that study not only surface electric potentials, but also inner neural sources appeared somewhat similar across perception and imagery conditions. For example, the intra-cranial reconstruction of movement-related imagery revealed a significant left-sided activation of cerebellum and fusiform gyrus, posterior parietal lobule (BA7), and other sensorimotor areas <ce:cross-ref id="crf0013" refid="bib0010">[10]</ce:cross-ref>. Source reconstruction related to musical imagery, on the other hand, showed significant activation of the left primary auditory area (BA41, Heschl's gyrus) and the right superior frontal gyrus (BA8), which are particularly involved in listening to and perceiving music.&#160;Overall, the similarity in morphology and brain sources across some late-latency ERP deflections associated with distinct visual categories appears to be consistent and robust enough to favor signal classification processes in the Brain-Computer Interface perspective. Indeed some studies have succeeded in classifying mental content of imagery through machine-learning algorithms such as MIRACLE <ce:cross-ref id="crf0014" refid="bib0011">[11]</ce:cross-ref> (<ce:italic>Mind Reading Classification Engine</ce:italic>). The authors were able to categorize 10 different domains of imagined entities (including 7 visual categories: infant face, adult face, human body, animal face, written word, tool, checkerboard), based on linked ERP signals, and similarly to what was done with perception <ce:cross-ref id="crf0015" refid="bib0012">[12]</ce:cross-ref>.</ce:para></ce:section></ce:sections><ce:conflict-of-interest id="coi0001" view="all"><ce:section-title id="cesectitle0005">Declaration of competing interest</ce:section-title><ce:para id="para0005" view="all">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</ce:para></ce:conflict-of-interest></ja:body><ja:simple-tail view="all"><ce:bibliography id="cebibl1" view="all"><ce:section-title id="cesectitle0006">References</ce:section-title><ce:bibliography-sec id="cebibsec1" view="all"><ce:bib-reference id="bib0001"><ce:label>[1]</ce:label><sb:reference id="sbref0001"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Dijkstra</ce:surname></sb:author><sb:author><ce:given-name>S.E.</ce:given-name><ce:surname>Bosch</ce:surname></sb:author><sb:author><ce:given-name>M.A.</ce:given-name><ce:surname>van Gerven</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Vividness of visual imagery depends on the neural overlap with perception in visual areas</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>J Neurosci</sb:maintitle></sb:title><sb:volume-nr>37</sb:volume-nr></sb:series><sb:issue-nr>5</sb:issue-nr><sb:date>2017</sb:date></sb:issue><sb:pages><sb:first-page>1367</sb:first-page><sb:last-page>1373</sb:last-page></sb:pages></sb:host><sb:comment>Feb 1</sb:comment></sb:reference><ce:source-text id="srctxt0001">Dijkstra N., Bosch S.E., van Gerven M.A. Vividness of visual imagery depends on the neural overlap with perception in visual areas. J Neurosci. 2017 Feb 1;37(5):1367&#x2013;73.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0002"><ce:label>[2]</ce:label><sb:reference id="sbref0002"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Spagna</ce:surname></sb:author><sb:author><ce:given-name>Z.</ce:given-name><ce:surname>Heidenry</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Miselevich</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Lambert</ce:surname></sb:author><sb:author><ce:given-name>B.E.</ce:given-name><ce:surname>Eisenstadt</ce:surname></sb:author><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Tremblay</ce:surname></sb:author><sb:author><ce:given-name>Z.</ce:given-name><ce:surname>Liu</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Liu</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Bartolomeo</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Visual mental imagery: evidence for a heterarchical neural architecture</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys Life Rev</sb:maintitle></sb:title></sb:series><sb:date>2023</sb:date></sb:issue><sb:pages><sb:first-page>113</sb:first-page><sb:last-page>131</sb:last-page></sb:pages></sb:host><sb:comment>this issue</sb:comment></sb:reference><ce:source-text id="srctxt0002">Spagna A., Heidenry Z., Miselevich M., Lambert C., Eisenstadt B.E., Tremblay L., Liu Z., Liu J., Bartolomeo P. Visual mental imagery: evidence for a heterarchical neural architecture. Phys Life Rev. 2023;113&#x2013;31, this issue.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0003"><ce:label>[3]</ce:label><sb:reference id="sbref0003"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Dijkstra</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Mostert</ce:surname></sb:author><sb:author><ce:given-name>F.P.</ce:given-name><ce:surname>Lange</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Bosch</ce:surname></sb:author><sb:author><ce:given-name>M.A.</ce:given-name><ce:surname>van Gerven</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Differential temporal dynamics during visual imagery and perception</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Elife</sb:maintitle></sb:title><sb:volume-nr>7</sb:volume-nr></sb:series><sb:date>2018</sb:date></sb:issue><sb:pages><sb:first-page>e33904</sb:first-page></sb:pages></sb:host><sb:comment>May 29</sb:comment></sb:reference><ce:source-text id="srctxt0003">Dijkstra N., Mostert P., Lange F.P., Bosch S., van Gerven M.A. Differential temporal dynamics during visual imagery and perception. Elife. 2018 May 29;7:e33904.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0004"><ce:label>[4]</ce:label><sb:reference id="sbref0004"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>S.H.</ce:given-name><ce:surname>Lee</ce:surname></sb:author><sb:author><ce:given-name>D.J.</ce:given-name><ce:surname>Kravitz</ce:surname></sb:author><sb:author><ce:given-name>C.I.</ce:given-name><ce:surname>Baker</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Disentangling visual imagery and perception of real-world objects</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Neuroimage</sb:maintitle></sb:title><sb:volume-nr>59</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>4064</sb:first-page><sb:last-page>4073</sb:last-page></sb:pages></sb:host><sb:comment>Feb 15</sb:comment></sb:reference><ce:source-text id="srctxt0004">Lee S.H., Kravitz D.J., Baker C.I. Disentangling visual imagery and perception of real-world objects. Neuroimage. 2012 Feb 15;59(4):4064&#x2013;73.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0005"><ce:label>[5]</ce:label><sb:reference id="sbref0005"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Xie</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Kaiser</ce:surname></sb:author><sb:author><ce:given-name>R.M.</ce:given-name><ce:surname>Cichy</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Visual imagery and perception share neural representations in the alpha frequency band</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Curr Biol</sb:maintitle></sb:title><sb:volume-nr>30</sb:volume-nr></sb:series><sb:issue-nr>15</sb:issue-nr><sb:date>2020</sb:date></sb:issue><sb:pages><sb:first-page>3062</sb:first-page></sb:pages></sb:host><sb:comment>Aug 3</sb:comment></sb:reference><ce:source-text id="srctxt0005">Xie S., Kaiser D., Cichy R.M. Visual imagery and perception share neural representations in the alpha frequency band. Curr Biol. 2020 Aug 3;30(15):3062.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0006"><ce:label>[6]</ce:label><sb:reference id="sbref0006"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.W.</ce:given-name><ce:surname>Page</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Duhamel</ce:surname></sb:author><sb:author><ce:given-name>M.A.</ce:given-name><ce:surname>Crognale</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>ERP evidence of visualization at early stages of visual processing</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Brain Cogn</sb:maintitle></sb:title><sb:volume-nr>75</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2011</sb:date></sb:issue><sb:pages><sb:first-page>141</sb:first-page><sb:last-page>146</sb:last-page></sb:pages></sb:host><sb:comment>Mar</sb:comment></sb:reference><ce:source-text id="srctxt0006">Page J.W., Duhamel P., Crognale M.A. ERP evidence of visualization at early stages of visual processing. Brain Cogn. 2011 Mar;75(2):141&#x2013;6.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0007"><ce:label>[7]</ce:label><sb:reference id="sbref0007"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>F.R.</ce:given-name><ce:surname>Llorella</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Patow</ce:surname></sb:author><sb:author><ce:given-name>J.M.</ce:given-name><ce:surname>Azor&#237;n</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Convolutional neural networks and genetic algorithm for visual imagery classification</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys Eng Sci Med</sb:maintitle></sb:title><sb:volume-nr>43</sb:volume-nr></sb:series><sb:issue-nr>3</sb:issue-nr><sb:date>2020</sb:date></sb:issue><sb:pages><sb:first-page>973</sb:first-page><sb:last-page>983</sb:last-page></sb:pages></sb:host><sb:comment>Sep</sb:comment></sb:reference><ce:source-text id="srctxt0007">Llorella F.R., Patow G., Azor&#237;n J.M. Convolutional neural networks and genetic algorithm for visual imagery classification. Phys Eng Sci Med. 2020 Sep;43(3):973&#x2013;83.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0008"><ce:label>[8]</ce:label><sb:reference id="sbref0008"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.C.</ce:given-name><ce:surname>Lanfranco</ce:surname></sb:author><sb:author><ce:given-name>&#193;.</ce:given-name><ce:surname>Rivera-Rei</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Huepe</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Ib&#225;&#241;ez</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Canales-Johnson</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Beyond imagination: hypnotic visual hallucination induces greater lateralised brain activity than visual mental imagery</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Neuroimage</sb:maintitle></sb:title><sb:volume-nr>239</sb:volume-nr></sb:series><sb:date>2021</sb:date></sb:issue><sb:article-number>118282</sb:article-number></sb:host><sb:comment>Oct 1</sb:comment></sb:reference><ce:source-text id="srctxt0008">Lanfranco R.C., Rivera-Rei &#193;., Huepe D., Ib&#225;&#241;ez A., Canales-Johnson A. Beyond imagination: hypnotic visual hallucination induces greater lateralised brain activity than visual mental imagery. Neuroimage. 2021 Oct 1;239:118282.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0009"><ce:label>[9]</ce:label><sb:reference id="sbref0009"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.M.</ce:given-name><ce:surname>Proverbio</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Tacchini</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Jiang</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>What do you have in mind? ERP markers of visual and auditory imagery</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Brain Cogn</sb:maintitle></sb:title><sb:volume-nr>166</sb:volume-nr></sb:series><sb:date>2023</sb:date></sb:issue><sb:article-number>105954</sb:article-number></sb:host><sb:comment>Mar</sb:comment></sb:reference><ce:source-text id="srctxt0009">Proverbio A.M., Tacchini M., Jiang K. What do you have in mind? ERP markers of visual and auditory imagery. Brain Cogn. 2023 Mar;166:105954.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0010"><ce:label>[10]</ce:label><sb:reference id="sbref0010"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.M.</ce:given-name><ce:surname>Proverbio</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Pischedda</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Measuring brain potentials of imagination linked to physiological needs and motivational states</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Front Hum Neurosci</sb:maintitle></sb:title><sb:volume-nr>17</sb:volume-nr></sb:series><sb:date>2023</sb:date></sb:issue><sb:article-number>1146789</sb:article-number><ce:doi>10.3389/fnhum.2023.1146789</ce:doi></sb:host><sb:comment>Mar 15</sb:comment></sb:reference><ce:source-text id="srctxt0010">Proverbio A.M., Pischedda F. Measuring brain potentials of imagination linked to physiological needs and motivational states. Front Hum Neurosci. 2023 Mar 15;17:1146789. doi: 10.3389/fnhum.2023.1146789.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0011"><ce:label>[11]</ce:label><sb:reference id="sbref0011"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Leoni</ce:surname></sb:author><sb:author><ce:given-name>S.C.</ce:given-name><ce:surname>Strada</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Tanelli</ce:surname></sb:author><sb:author><ce:given-name>A.M.</ce:given-name><ce:surname>Proverbio</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Miracle: mind reading classification engine</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Trans Neural Syst Rehabil Eng</sb:maintitle></sb:title><sb:volume-nr>31</sb:volume-nr></sb:series><sb:date>2023</sb:date></sb:issue><sb:pages><sb:first-page>3212</sb:first-page><sb:last-page>3222</sb:last-page></sb:pages></sb:host></sb:reference><ce:source-text id="srctxt0011">Leoni J., Strada S.C., Tanelli M., Proverbio A.M. Miracle: mind reading classification engine. IEEE Trans Neural Syst Rehabil Eng. 2023;31:3212&#x2013;22.</ce:source-text></ce:bib-reference><ce:bib-reference id="bib0012"><ce:label>[12]</ce:label><sb:reference id="sbref0012"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Leoni</ce:surname></sb:author><sb:author><ce:given-name>S.C.</ce:given-name><ce:surname>Strada</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Tanelli</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Jiang</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Brusa</ce:surname></sb:author><sb:author><ce:given-name>A.M.</ce:given-name><ce:surname>Proverbio</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Automatic stimuli classification from ERP data for augmented communication via brain-computer interfaces</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Expert Syst Appl</sb:maintitle></sb:title><sb:volume-nr>184</sb:volume-nr></sb:series><sb:date>2021</sb:date></sb:issue><sb:article-number>115572</sb:article-number><ce:doi>10.1016/j.eswa.2021.115572</ce:doi></sb:host></sb:reference><ce:source-text id="srctxt0012">Leoni J., Strada S.C., Tanelli M., Jiang K., Brusa A., Proverbio A.M. Automatic stimuli classification from ERP data for augmented communication via brain-computer interfaces. Expert Syst Appl. 2021; 184, 115572 10.1016/j.eswa.2021.115572.</ce:source-text></ce:bib-reference></ce:bibliography-sec></ce:bibliography></ja:simple-tail></ja:simple-article></doc:document>
